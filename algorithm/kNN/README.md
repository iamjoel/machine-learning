# k-邻近算法(kNN)
一个样本在特征空间中的k个最相邻的样本中的大多数属于某一个类别，则该样本也属于这个类别。k一般选20。

举个例子：k为20。对某部电影做分类，对所有样本数据的相似度从小排序大排序，取前20部，其中15部是爱情电影，4部是恐怖电影，1部是动作电影。则该电影是爱情电影。

优点: 精度高， 对异常值不敏感， 无数据输入假定
缺点: 计算复杂度高，空间复杂度高
适用范围: 数值型和标称行。

标称型：标称型目标变量的结果只在有限目标集中取值，标称型目标变量主要用于分类。
数值型：数值型目标变量则可以从无限的数值集合中取值，如0.100，42.001等。数值型目标变量主要用于回归分析。

## 归一化数值
不同特征的数字范围不一样，特征值大对距离的结果有较大的影响，如 数据1:(1000, 1) 数据2: (3000, 0.4)。因此，为排除这种影响，要将每个值进行标准归一化，都变成 0 到 1 的之间的数。  
```
var dataSet = [arr1, arr2, arr3 ,...]
var feature1 = dataSet.map(row => row[0])
var max1 = Math.max(...feature1)
var min1 = Math.min(...feature1)

var currData = [f1, f2, ...]
currData[0] = (f1 - min1)/(max1 - min1)
```

## 计算特征值的相似性
判断数据的相似度，其实也就是计算两个矩阵的欧式距离(各特征值的差值的平方求和 再开平方)。  
```
function distance(arr1, arr2) {
  var sum = 0
  arr1.forEach((item1,index) => {
    let item2 = arr2[index]
    sum += Math.pow(item2 - item1, 2)
  })
  return Math.sqrt(sum)
}
```

## 其他说明
用 邻近算法 ，必须将特征值转化为向量。如 处理 `32*32` 的图片识别问题，会处理成 `1*1024(=32*32)` 的向量。